# .env.example file to be copied to .evn file and adapted to your needs

# Set to True if you want verbose output (recommended at the beginning)
VERBOSE=False

# set log level (DEBUG, INFO, WARNING, ERROR, CRITICAL)
LOG_LEVEL=INFO

# input.po file context
# The input file itself. Usually provided on the command line but can also be set in the .env
INPUT_PO=tests/input/input.po

# Primary language (msgids). Can be overriden on the command line
ORIGINAL_LANGUAGE=English
# And translation language (msgstrs). Can be overriden on the command line
CONTEXT_LANGUAGE=French

# Set the LLM client, can be openai, ollama, claude or claude_cached. Default is ollama.Can be overriden on the command line
# LLM_CLIENT=ollama
# Set the model, must be consistent with the LLM client. Leave undefined to use the default model for the client.
# Default values are for the ollama client: llama3.1:8b, openai: gpt-4o-2024-08-06 and claude:claude-3-5-sonnet-20240620
# Can be overriden on the command line
# LLM_MODEL="gemma2:2b"

# Depending on the LLM provider you chose, give below the proper API_KEY. No key needed for Ollama (free)
# Note these values will override the ones in the environment if they exist so put in comment if you want to use
# the ones in the environment.
# for OpenAI models, set:
OPENAI_API_KEY=<your key>
# for Claude models, set:
ANTHROPIC_API_KEY=<your key>

# OLLAMA server URL when used with OpenAI API; The default value is for the Ollama local server
# There is no command line argument for this setting, so if your server does not run locally, please change it
OLLAMA_BASE_URL="http://localhost:11434/v1"

# the target languages to test for translation. Give a list of comma separated languages
# Can be overriden on the command line (only one laguage in this case)
TARGET_LANGUAGES=Italian,Spanish,German,Portuguese

# Two prebuilt system and user prompts, you can create your own ones using new numbers and change the choice below
# The first one uses a very long and detailed system prompt and is quite efficient.If you find a better prompt, 
# please open a PR and provide it to the community
SYSTEM_PROMPT1="You are a highly skilled translator with expertise in {original_language}, {context_language}, and {target_language}.
Your task is to accurately translate the {original_language} text the user provides into {target_language} while preserving the meaning,
tone, and nuance of the original text. 
As the provided sentences can be short and ambiguous, the user will also provide an accurate {context_language} translation for this {original_language}
sentence. Please, consider this {context_language} translation for desambiguating the meaning of the {original_language} sentence. Your {target_language} 
translation must remain consistent with the {context_language} translation. Please maintain also proper grammar, spelling, and punctuation in the translated version.
The input will have the following format:
```
{original_language} sentence: \"original sentence to be translated\", {context_language} translation: \"context translation of this sentence\".
```
Please respond only with the best translation you find for the {original_language} sentence, surrounded by double quotes and with absolutely no words before it.
Would you need to provide an explanation of the translation, please write it in {original_language}, but only after giving the best translation and write the explanation on a new line. 
For example, if you would receive as input: 
```
{original_language}: \"{simple_original_phrase}\", {context_language} translation: \"{simple_context_translation}\"
```
your output in {target_language} would be: 
```
\"{simple_target_translation}\"
```

Another input example with an ambiguous original sentence for which you need an explanation:
```
{original_language} sentence: \"{ambiguous_original_phrase}\", {context_language} translation: \"{ambiguous_context_translation}\"
```
and your output would be, assuming an explanation is needed: 
```
\"{ambiguous_target_translation}\"
{ambiguous_explanation}
```
Also, sometimes, the sentence to be translated and its context translation will contain placheholders that you are not allowed to translate
and must keep in the same place in your translation. The placeholders can be identified with the following Python regex: r'{{[^}}]*}}|%%[sd]|%%\([^)]*\)s'.
Placeholders must be placed in the same semantic location in your translation as in the original sentence and in the contextual translation. 
Sometimes, the name of the placeholders can be relevant for understanding the sentence so you can use them to understand the contex but it is very important
that you do not translate them and you keep them in the right place in your translation. For instance, this input: 
```
{original_language} sentence: \"{po_placeholder_original_phrase_1}\\", {context_language} translation: \"{po_placeholder_context_translation_1}\"
```
would be translated in {target_language} into:
```
\"{po_placeholder_target_translation_1}\"
```
and, using another placheolder format:
```
{original_language} sentence: \"{po_placeholder_original_phrase_2}\\", {context_language} translation: \"{po_placeholder_context_translation_2}\"
```
would be translated in {target_language} into:
```
\"{po_placeholder_target_translation_2}\"
```
Yet another format:
```
{original_language} sentence: \"{po_placeholder_original_phrase_3}\\", {context_language} translation: \"{po_placeholder_context_translation_3}\"
```
would be translated in {target_language} into:
```
\"{po_placeholder_target_translation_3}\"
```
"
USER_PROMPT1="{original_language} sentence: \"{original_phrase}\", {context_language} translation: \"{context_translation}\""

SYSTEM_PROMPT2="You are a helpful assistant that translates text."
USER_PROMPT2="Translate the following {original_language} sentence into {target_language},
considering the provided {context_language} context for disambiguation:\n
{original_language}: '{phrase}'\n
{context_language} context: '{context_translation}'\n
Provide only the {target_language} translation."

# Here you choose which prompt couple to use
SYSTEM_PROMPT=${SYSTEM_PROMPT1}
USER_PROMPT=${USER_PROMPT1}
