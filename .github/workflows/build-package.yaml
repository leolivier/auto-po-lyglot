# This workflow will install Python dependencies, run tests and lint with a variety of Python versions
# For more information see: https://docs.github.com/en/actions/automating-builds-and-tests/building-and-testing-python

name: Python package

on:
  push:
    branches: [ "main", "pypi-packaging" ]
  pull_request:
    branches: [ "main" ]


env:
  LLM_CLIENT: ollama
  MODEL: gemma2:2b
  VERBOSE: true # optional
  INPUT_PO: tests/input/input.po
  ORIGINAL_LANGUAGE: English
  CONTEXT_LANGUAGE: French
  TARGET_LANGUAGES: Italian  # comma separated list
  OLLAMA_BASE_URL: "http://localhost:11434/v1"
  # 2 files used to cache the Ollama version and model list
  # so that they do not need to be downloaded every time
  # Touch this file to force it to update Ollama
  OLLAMA_VERSION_FILE: '.github/workflows/ollama-version.txt'
  # Put in this file a list of all models you want to pull from Ollama, one per line. 
  # MODEL must be set to one of these
  MODEL_LIST_FILE: '.github/workflows/model-list.txt'

jobs:

  ollama-job:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout code
        uses: actions/checkout@v3

      - name: Display Ollama version
        run: |
          echo "Ollama version file content:"
          cat ${{ env.OLLAMA_VERSION_FILE }}
          echo "Ollama version hash:"
          echo ${{ hashFiles(env.OLLAMA_VERSION_FILE) }}

      - name: Cache Ollama
        uses: actions/cache@v3
        id: cache-ollama
        with:
          path: ~/.ollama
          key: ${{ runner.os }}-ollama-${{ hashFiles(env.OLLAMA_VERSION_FILE) }}
          restore-keys: |
            ${{ runner.os }}-ollama-

      - name: Debug Cache Ollama
        run: |
          echo "Cache hit: ${{ steps.cache-ollama.outputs.cache-hit }}"
          if [ "${{ steps.cache-ollama.outputs.cache-hit }}" != 'true' ]; then
            echo "Cache miss. This is normal if this is the first run or if the Ollama version has changed."
          fi

      - name: Install or Use Cached Ollama
        run: |
          if [ ! -f ~/.ollama/bin/ollama ]; then
            echo "Installing Ollama"
            curl https://ollama.ai/install.sh | sh
            mkdir -p ~/.ollama/bin
            cp /usr/local/bin/ollama ~/.ollama/bin/ollama
          else
            echo "Using cached Ollama"
          fi
          sudo ln -sf ~/.ollama/bin/ollama /usr/local/bin/ollama
          ollama --version

      - name: Start Ollama and wait for it to serve
        run: |
          ollama serve &
          sleep 10

      - name: Cache Ollama models
        uses: actions/cache@v3
        id: cache-models
        with:
          path: ~/.ollama/models
          key: ${{ runner.os }}-ollama-models-${{ hashFiles(env.MODEL_LIST_FILE) }}

      - name: Debug Cache Models
        run: |
          echo "Models cache hit: ${{ steps.cache-models.outputs.cache-hit }}"
          if [ "${{ steps.cache-models.outputs.cache-hit }}" != 'true' ]; then
            echo "Models cache miss. This is normal if this is the first run or if the model list has changed."
          fi

      - name: Pull Ollama models
        run: |
          while IFS= read -r model || [[ -n "$model" ]]; do
            if [ ! -f ~/.ollama/models/${model}.bin ]; then
              echo "Pulling model: $model"
              ollama pull $model
            else
              echo "Model already cached: $model"
            fi
          done < ${{ env.MODEL_LIST_FILE }}
          ollama list

      - name: Debug final state
        if: always()
        run: |
          echo "Ollama version:"
          ollama --version
          echo "Available models:"
          ollama list
          echo "Ollama directory content:"
          ls -R ~/.ollama

      - name: Set up Python 3.10
        uses: actions/setup-python@v5
        with:
          python-version: '3.10'
          cache: 'pip'

      - name: Create Venv and Install dependencies
        run: |
          python -m pip install --upgrade pip
          python -m pip install --upgrade uv  # install python manager
          uv sync  # create a virtual environment and install dependencies
          source .venv/bin/activate  # activate the virtual environment
          uv pip install -e .  # to allow dev package testing

      - name: Lint with flake8
        run: |
          # stop the build if there are Python syntax errors or undefined names
          uv run flake8 ./src ./tests --count --select=E9,F63,F7,F82 --show-source --statistics
          # exit-zero treats all errors as warnings. The GitHub editor is 127 chars wide
          uv run flake8 ./src ./tests --count --exit-zero --max-complexity=10 --max-line-length=127 --indent-size 2 --statistics

      - name: Make envfile
        uses: SpicyPizza/create-envfile@v2.0.3
        with:
          envkey_VERBOSE: ${{ env.VERBOSE }} # optional
          envkey_INPUT_PO: ${{ env.INPUT_PO }}
          envkey_ORIGINAL_LANGUAGE: ${{ env.ORIGINAL_LANGUAGE }}
          envkey_CONTEXT_LANGUAGE: ${{ env.CONTEXT_LANGUAGE }}
          envkey_TARGET_LANGUAGES: ${{ env.TARGET_LANGUAGES }}
          envkey_LLM_CLIENT: ${{ env.LLM_CLIENT }}
          envkey_LLM_MODEL: ${{ env.MODEL }}
          envkey_OLLAMA_BASE_URL: ${{ env.OLLAMA_BASE_URL }}
          envkey_SYSTEM_PROMPT: ${{ vars.SYSTEM_PROMPT }}
          envkey_USER_PROMPT: ${{ vars.USER_PROMPT }}
          directory: .
          file_name: .env
          fail_on_empty: false
          sort_keys: false

      - name: Test with pytest
        run: |
          # [[ -f .env ]] && cat .env || echo "No .env file found in root"
          # [[ -f tests/.env ]] && cat tests/.env || echo "No .env file found in tests"
          uv run pytest -s ./tests